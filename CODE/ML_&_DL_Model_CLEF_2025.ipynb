{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LB0X0jnO7Ruw",
        "outputId": "47c75233-9569-480f-f961-84c40a8b6eb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Simple Subjectivity Detection Pipeline\n",
            "==================================================\n",
            "üìÇ Loading data...\n",
            "‚úÖ Train samples: 1292\n",
            "‚úÖ Test samples: 300\n",
            "üìä Label distribution: {'OBJ': 754, 'SUBJ': 538}\n",
            "\n",
            "ü§ñ Training Traditional ML Models\n",
            "----------------------------------------\n",
            "üìù Creating TF-IDF features...\n",
            "\n",
            "üî• Training Naive Bayes...\n",
            "‚úÖ Naive Bayes Results:\n",
            "   üìä Accuracy: 0.6533\n",
            "   üéØ F1 Score: 0.6415\n",
            "\n",
            "   Confusion Matrix:\n",
            "             Predicted OBJ  Predicted SUBJ\n",
            "Actual OBJ             171              44\n",
            "Actual SUBJ             60              25\n",
            "\n",
            "   Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         OBJ       0.74      0.80      0.77       215\n",
            "        SUBJ       0.36      0.29      0.32        85\n",
            "\n",
            "    accuracy                           0.65       300\n",
            "   macro avg       0.55      0.54      0.55       300\n",
            "weighted avg       0.63      0.65      0.64       300\n",
            "\n",
            "\n",
            "üî• Training SVM...\n",
            "‚úÖ SVM Results:\n",
            "   üìä Accuracy: 0.5833\n",
            "   üéØ F1 Score: 0.5937\n",
            "\n",
            "   Confusion Matrix:\n",
            "             Predicted OBJ  Predicted SUBJ\n",
            "Actual OBJ             144              71\n",
            "Actual SUBJ             54              31\n",
            "\n",
            "   Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         OBJ       0.73      0.67      0.70       215\n",
            "        SUBJ       0.30      0.36      0.33        85\n",
            "\n",
            "    accuracy                           0.58       300\n",
            "   macro avg       0.52      0.52      0.51       300\n",
            "weighted avg       0.61      0.58      0.59       300\n",
            "\n",
            "\n",
            "üî• Training Random Forest...\n",
            "‚úÖ Random Forest Results:\n",
            "   üìä Accuracy: 0.6100\n",
            "   üéØ F1 Score: 0.5977\n",
            "\n",
            "   Confusion Matrix:\n",
            "             Predicted OBJ  Predicted SUBJ\n",
            "Actual OBJ             164              51\n",
            "Actual SUBJ             66              19\n",
            "\n",
            "   Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         OBJ       0.71      0.76      0.74       215\n",
            "        SUBJ       0.27      0.22      0.25        85\n",
            "\n",
            "    accuracy                           0.61       300\n",
            "   macro avg       0.49      0.49      0.49       300\n",
            "weighted avg       0.59      0.61      0.60       300\n",
            "\n",
            "\n",
            "============================================================\n",
            "üèÜ FINAL RESULTS COMPARISON\n",
            "============================================================\n",
            "\n",
            "ü§ñ Traditional ML Models:\n",
            "   Naive Bayes    : Accuracy=0.6533, F1=0.6415\n",
            "   SVM            : Accuracy=0.5833, F1=0.5937\n",
            "   Random Forest  : Accuracy=0.6100, F1=0.5977\n",
            "\n",
            "ü•á BEST ML MODEL: Naive Bayes (F1: 0.6415)\n",
            "\n",
            "Detailed Report for Best ML Model: Naive Bayes\n",
            "Confusion Matrix:\n",
            "             Predicted OBJ  Predicted SUBJ\n",
            "Actual OBJ             171              44\n",
            "Actual SUBJ             60              25\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         OBJ       0.74      0.80      0.77       215\n",
            "        SUBJ       0.36      0.29      0.32        85\n",
            "\n",
            "    accuracy                           0.65       300\n",
            "   macro avg       0.55      0.54      0.55       300\n",
            "weighted avg       0.63      0.65      0.64       300\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Simple Subjectivity Detection - 3 ML + 3 DL Models\n",
        "# Easy to understand and run\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
        "\n",
        "# ML Models\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# DL Models\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, AutoModel, TrainingArguments, Trainer\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Disable wandb\n",
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "print(\"üöÄ Simple Subjectivity Detection Pipeline\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# ===== DATA LOADING =====\n",
        "def load_data():\n",
        "    \"\"\"Load and prepare data\"\"\"\n",
        "    print(\"üìÇ Loading data...\")\n",
        "\n",
        "    train_df = pd.read_csv('train_en.tsv', sep='\\t')\n",
        "    dev_df = pd.read_csv('dev_en.tsv', sep='\\t')\n",
        "    test_df = pd.read_csv('test_en_labeled.tsv', sep='\\t')\n",
        "\n",
        "    # Combine train and dev for more data\n",
        "    full_train = pd.concat([train_df, dev_df], ignore_index=True)\n",
        "\n",
        "    # Clean data\n",
        "    full_train = full_train.dropna(subset=['sentence', 'label'])\n",
        "    test_df = test_df.dropna(subset=['sentence', 'label'])\n",
        "\n",
        "    # Convert labels\n",
        "    label_map = {'SUBJ': 1, 'OBJ': 0}\n",
        "    full_train['label_num'] = full_train['label'].map(label_map)\n",
        "    test_df['label_num'] = test_df['label'].map(label_map)\n",
        "\n",
        "    print(f\"‚úÖ Train samples: {len(full_train)}\")\n",
        "    print(f\"‚úÖ Test samples: {len(test_df)}\")\n",
        "    print(f\"üìä Label distribution: {full_train['label'].value_counts().to_dict()}\")\n",
        "\n",
        "    return full_train, test_df\n",
        "\n",
        "# ===== TRADITIONAL ML MODELS =====\n",
        "def train_ml_models(train_df, test_df):\n",
        "    \"\"\"Train 3 ML models and report results including confusion matrix\"\"\"\n",
        "    print(\"\\nü§ñ Training Traditional ML Models\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    # Prepare data\n",
        "    X_train = train_df['sentence'].values\n",
        "    y_train = train_df['label_num'].values\n",
        "    X_test = test_df['sentence'].values\n",
        "    y_test = test_df['label_num'].values\n",
        "\n",
        "    # TF-IDF Vectorization\n",
        "    print(\"üìù Creating TF-IDF features...\")\n",
        "    vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')\n",
        "    X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "    X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "    # Models\n",
        "    models = {\n",
        "        'Naive Bayes': MultinomialNB(),\n",
        "        'SVM': SVC(kernel='linear', random_state=42),\n",
        "        'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    }\n",
        "\n",
        "    ml_results = {}\n",
        "\n",
        "    for name, model in models.items():\n",
        "        print(f\"\\nüî• Training {name}...\")\n",
        "\n",
        "        # Train\n",
        "        model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "        # Predict\n",
        "        y_pred = model.predict(X_test_tfidf)\n",
        "\n",
        "        # Metrics\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "        class_report = classification_report(y_test, y_pred, target_names=['OBJ', 'SUBJ']) # Assuming 0: OBJ, 1: SUBJ\n",
        "\n",
        "        print(f\"‚úÖ {name} Results:\")\n",
        "        print(f\"   üìä Accuracy: {accuracy:.4f}\")\n",
        "        print(f\"   üéØ F1 Score: {f1:.4f}\")\n",
        "        print(\"\\n   Confusion Matrix:\")\n",
        "        # Using pandas to display the confusion matrix with labels for better readability\n",
        "        cm_df = pd.DataFrame(conf_matrix, index=['Actual OBJ', 'Actual SUBJ'], columns=['Predicted OBJ', 'Predicted SUBJ'])\n",
        "        print(cm_df)\n",
        "        print(\"\\n   Classification Report:\")\n",
        "        print(class_report)\n",
        "\n",
        "\n",
        "        ml_results[name] = {\n",
        "            'accuracy': accuracy,\n",
        "            'f1_score': f1,\n",
        "            'predictions': y_pred,\n",
        "            'confusion_matrix': conf_matrix, # Store confusion matrix\n",
        "            'classification_report': class_report # Store classification report\n",
        "        }\n",
        "\n",
        "    return ml_results\n",
        "\n",
        "\n",
        "# ===== MAIN FUNCTION =====\n",
        "def main():\n",
        "    \"\"\"Main execution\"\"\"\n",
        "    # Load data\n",
        "    train_df, test_df = load_data()\n",
        "\n",
        "    # Train ML models\n",
        "    ml_results = train_ml_models(train_df, test_df)\n",
        "\n",
        "    # Final comparison\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"üèÜ FINAL RESULTS COMPARISON\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    print(\"\\nü§ñ Traditional ML Models:\")\n",
        "    best_ml_f1 = 0\n",
        "    best_ml_model = \"\"\n",
        "\n",
        "    for model_name, results in ml_results.items():\n",
        "        print(f\"   {model_name:<15}: Accuracy={results['accuracy']:.4f}, F1={results['f1_score']:.4f}\")\n",
        "        if results['f1_score'] > best_ml_f1:\n",
        "            best_ml_f1 = results['f1_score']\n",
        "            best_ml_model = model_name\n",
        "\n",
        "    print(f\"\\nü•á BEST ML MODEL: {best_ml_model} (F1: {best_ml_f1:.4f})\")\n",
        "\n",
        "    # Optional: Print detailed report for the best ML model again\n",
        "    if best_ml_model:\n",
        "        print(f\"\\nDetailed Report for Best ML Model: {best_ml_model}\")\n",
        "        print(\"Confusion Matrix:\")\n",
        "        cm_df = pd.DataFrame(ml_results[best_ml_model]['confusion_matrix'], index=['Actual OBJ', 'Actual SUBJ'], columns=['Predicted OBJ', 'Predicted SUBJ'])\n",
        "        print(cm_df)\n",
        "        print(\"\\nClassification Report:\")\n",
        "        print(ml_results[best_ml_model]['classification_report'])\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple & Precise Subjectivity Detection - 3 Deep Learning Models\n",
        "# Models: CNN, LSTM, CNN+LSTM Combined\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import Adam\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix # Import confusion_matrix\n",
        "from collections import Counter\n",
        "import re\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# =============================================================================\n",
        "# 1. SIMPLE TEXT PREPROCESSING\n",
        "# =============================================================================\n",
        "\n",
        "def build_vocab(texts, max_vocab=20000):\n",
        "    \"\"\"Build vocabulary from texts\"\"\"\n",
        "    print(\"Building vocabulary...\")\n",
        "\n",
        "    # Clean and tokenize\n",
        "    all_words = []\n",
        "    for text in texts:\n",
        "        words = str(text).lower().split()\n",
        "        all_words.extend(words)\n",
        "\n",
        "    # Count frequencies\n",
        "    word_counts = Counter(all_words)\n",
        "\n",
        "    # Create vocab\n",
        "    vocab = {'<PAD>': 0, '<UNK>': 1}\n",
        "    for word, count in word_counts.most_common(max_vocab-2):\n",
        "        vocab[word] = len(vocab)\n",
        "\n",
        "    print(f\"Vocabulary size: {len(vocab)}\")\n",
        "    return vocab\n",
        "\n",
        "def text_to_sequence(text, vocab, max_len=100):\n",
        "    \"\"\"Convert text to sequence of numbers\"\"\"\n",
        "    words = str(text).lower().split()\n",
        "    sequence = [vocab.get(word, 1) for word in words]  # 1 = <UNK>\n",
        "\n",
        "    # Pad or truncate\n",
        "    if len(sequence) > max_len:\n",
        "        sequence = sequence[:max_len]\n",
        "    else:\n",
        "        sequence += [0] * (max_len - len(sequence))  # 0 = <PAD>\n",
        "\n",
        "    return sequence\n",
        "\n",
        "# =============================================================================\n",
        "# 2. DATASET CLASS\n",
        "# =============================================================================\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, labels, vocab, max_len=100):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.vocab = vocab\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        sequence = text_to_sequence(text, self.vocab, self.max_len)\n",
        "\n",
        "        return {\n",
        "            'text': torch.tensor(sequence, dtype=torch.long),\n",
        "            'label': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "# =============================================================================\n",
        "# 3. MODEL 1: CNN MODEL\n",
        "# =============================================================================\n",
        "\n",
        "class CNNModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim=128, num_filters=100):\n",
        "        super().__init__()\n",
        "\n",
        "        # Embedding layer\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
        "\n",
        "        # CNN layers with different filter sizes\n",
        "        self.conv1 = nn.Conv1d(embed_dim, num_filters, kernel_size=3)\n",
        "        self.conv2 = nn.Conv1d(embed_dim, num_filters, kernel_size=4)\n",
        "        self.conv3 = nn.Conv1d(embed_dim, num_filters, kernel_size=5)\n",
        "\n",
        "        # Classification layers\n",
        "        self.fc1 = nn.Linear(num_filters * 3, 128)\n",
        "        self.fc2 = nn.Linear(128, 2)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Embedding\n",
        "        embedded = self.embedding(x)  # (batch, seq_len, embed_dim)\n",
        "        embedded = embedded.transpose(1, 2)  # (batch, embed_dim, seq_len)\n",
        "\n",
        "        # CNN features\n",
        "        conv1_out = F.relu(self.conv1(embedded))\n",
        "        conv2_out = F.relu(self.conv2(embedded))\n",
        "        conv3_out = F.relu(self.conv3(embedded))\n",
        "\n",
        "        # Global max pooling\n",
        "        pool1 = F.max_pool1d(conv1_out, conv1_out.size(2)).squeeze(2)\n",
        "        pool2 = F.max_pool1d(conv2_out, conv2_out.size(2)).squeeze(2)\n",
        "        pool3 = F.max_pool1d(conv3_out, conv3_out.size(2)).squeeze(2)\n",
        "\n",
        "        # Concatenate features\n",
        "        features = torch.cat([pool1, pool2, pool3], dim=1)\n",
        "\n",
        "        # Classification\n",
        "        x = F.relu(self.fc1(features))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# =============================================================================\n",
        "# 4. MODEL 2: LSTM MODEL\n",
        "# =============================================================================\n",
        "\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim=128, hidden_dim=128):\n",
        "        super().__init__()\n",
        "\n",
        "        # Embedding layer\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
        "\n",
        "        # LSTM layer\n",
        "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True,\n",
        "                           num_layers=2, dropout=0.3, bidirectional=True)\n",
        "\n",
        "        # Classification layers\n",
        "        self.fc1 = nn.Linear(hidden_dim * 2, 128)  # *2 for bidirectional\n",
        "        self.fc2 = nn.Linear(128, 2)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Embedding\n",
        "        embedded = self.embedding(x)\n",
        "\n",
        "        # LSTM\n",
        "        lstm_out, (hidden, cell) = self.lstm(embedded)\n",
        "\n",
        "        # Use last hidden state from both directions\n",
        "        hidden = torch.cat([hidden[-2], hidden[-1]], dim=1)\n",
        "\n",
        "        # Classification\n",
        "        x = F.relu(self.fc1(hidden))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# =============================================================================\n",
        "# 5. MODEL 3: CNN + LSTM COMBINED\n",
        "# =============================================================================\n",
        "\n",
        "class CNNLSTMModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim=128, hidden_dim=128, num_filters=64):\n",
        "        super().__init__()\n",
        "\n",
        "        # Embedding layer\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
        "\n",
        "        # CNN branch\n",
        "        self.conv1 = nn.Conv1d(embed_dim, num_filters, kernel_size=3)\n",
        "        self.conv2 = nn.Conv1d(embed_dim, num_filters, kernel_size=5)\n",
        "\n",
        "        # LSTM branch\n",
        "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True,\n",
        "                           bidirectional=True)\n",
        "\n",
        "        # Combined features\n",
        "        combined_dim = (num_filters * 2) + (hidden_dim * 2)\n",
        "\n",
        "        # Classification layers\n",
        "        self.fc1 = nn.Linear(combined_dim, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, 2)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Embedding\n",
        "        embedded = self.embedding(x)\n",
        "\n",
        "        # CNN branch\n",
        "        cnn_input = embedded.transpose(1, 2)\n",
        "        conv1_out = F.relu(self.conv1(cnn_input))\n",
        "        conv2_out = F.relu(self.conv2(cnn_input))\n",
        "\n",
        "        # Global max pooling for CNN\n",
        "        cnn_pool1 = F.max_pool1d(conv1_out, conv1_out.size(2)).squeeze(2)\n",
        "        cnn_pool2 = F.max_pool1d(conv2_out, conv2_out.size(2)).squeeze(2)\n",
        "        cnn_features = torch.cat([cnn_pool1, cnn_pool2], dim=1)\n",
        "\n",
        "        # LSTM branch\n",
        "        lstm_out, (hidden, cell) = self.lstm(embedded)\n",
        "        lstm_features = torch.cat([hidden[-2], hidden[-1]], dim=1)\n",
        "\n",
        "        # Combine CNN and LSTM features\n",
        "        combined = torch.cat([cnn_features, lstm_features], dim=1)\n",
        "\n",
        "        # Classification\n",
        "        x = F.relu(self.fc1(combined))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# =============================================================================\n",
        "# 6. TRAINING FUNCTION\n",
        "# =============================================================================\n",
        "\n",
        "def train_model(model, train_loader, val_loader, epochs=10, lr=0.001):\n",
        "    \"\"\"Train any model\"\"\"\n",
        "    optimizer = Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    best_f1 = 0\n",
        "    best_model = None\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Training\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "\n",
        "        for batch in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            texts = batch['text'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            outputs = model(texts)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        # Validation\n",
        "        # Update to unpack all 4 returned values from evaluate_model\n",
        "        val_acc, val_f1, _, _ = evaluate_model(model, val_loader)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
        "        print(f\"Train Loss: {train_loss/len(train_loader):.4f}\")\n",
        "        print(f\"Val Accuracy: {val_acc:.4f}, Val F1: {val_f1:.4f}\")\n",
        "\n",
        "        # Save best model\n",
        "        if val_f1 > best_f1:\n",
        "            best_f1 = val_f1\n",
        "            best_model = model.state_dict().copy()\n",
        "\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "    # Load best model\n",
        "    model.load_state_dict(best_model)\n",
        "    return model\n",
        "# =============================================================================\n",
        "# 7. EVALUATION FUNCTION\n",
        "# =============================================================================\n",
        "\n",
        "def evaluate_model(model, data_loader):\n",
        "    \"\"\"Evaluate model and return predictions and true labels\"\"\"\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    true_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            texts = batch['text'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            outputs = model(texts)\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "\n",
        "            predictions.extend(preds.cpu().numpy())\n",
        "            true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    accuracy = accuracy_score(true_labels, predictions)\n",
        "    f1 = f1_score(true_labels, predictions, average='weighted')\n",
        "\n",
        "    return accuracy, f1, true_labels, predictions # Return true_labels and predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95JNV8CTM_XZ",
        "outputId": "28ccdbde-8ee4-4a86-90c7-f69d12829e9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# 8. MAIN FUNCTION\n",
        "# =============================================================================\n",
        "\n",
        "def main():\n",
        "    print(\"Loading datasets...\")\n",
        "\n",
        "    # Load data\n",
        "    train_df = pd.read_csv('train_en.tsv', sep='\\t')\n",
        "    dev_df = pd.read_csv('dev_en.tsv', sep='\\t')\n",
        "    test_df = pd.read_csv('test_en_labeled.tsv', sep='\\t')\n",
        "\n",
        "    # Convert labels\n",
        "    label_map = {'SUBJ': 1, 'OBJ': 0}\n",
        "    train_df['label_num'] = train_df['label'].map(label_map)\n",
        "    dev_df['label_num'] = dev_df['label'].map(label_map)\n",
        "    test_df['label_num'] = test_df['label'].map(label_map)\n",
        "\n",
        "    print(f\"Train: {len(train_df)}, Dev: {len(dev_df)}, Test: {len(test_df)}\")\n",
        "\n",
        "    # Build vocabulary\n",
        "    all_texts = list(train_df['sentence']) + list(dev_df['sentence'])\n",
        "    vocab = build_vocab(all_texts)\n",
        "\n",
        "    # Create datasets\n",
        "    max_len = 100\n",
        "    batch_size = 32\n",
        "\n",
        "    train_dataset = TextDataset(train_df['sentence'], train_df['label_num'], vocab, max_len)\n",
        "    dev_dataset = TextDataset(dev_df['sentence'], dev_df['label_num'], vocab, max_len)\n",
        "    test_dataset = TextDataset(test_df['sentence'], test_df['label_num'], vocab, max_len)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    dev_loader = DataLoader(dev_dataset, batch_size=batch_size)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "    vocab_size = len(vocab)\n",
        "\n",
        "    # =============================================================================\n",
        "    # MODEL 1: CNN\n",
        "    # =============================================================================\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"TRAINING CNN MODEL\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    cnn_model = CNNModel(vocab_size).to(device)\n",
        "    print(f\"CNN Parameters: {sum(p.numel() for p in cnn_model.parameters()):,}\")\n",
        "\n",
        "    cnn_model = train_model(cnn_model, train_loader, dev_loader, epochs=8)\n",
        "\n",
        "    # Test CNN\n",
        "    cnn_test_acc, cnn_test_f1, cnn_true, cnn_pred = evaluate_model(cnn_model, test_loader)\n",
        "    print(f\"CNN Test - Accuracy: {cnn_test_acc:.4f}, F1: {cnn_test_f1:.4f}\")\n",
        "    print(\"\\nCNN Confusion Matrix:\")\n",
        "    cnn_conf_matrix = confusion_matrix(cnn_true, cnn_pred)\n",
        "    cm_df_cnn = pd.DataFrame(cnn_conf_matrix, index=['Actual OBJ', 'Actual SUBJ'], columns=['Predicted OBJ', 'Predicted SUBJ'])\n",
        "    print(cm_df_cnn)\n",
        "    print(\"\\nCNN Classification Report:\")\n",
        "    print(classification_report(cnn_true, cnn_pred, target_names=['OBJ', 'SUBJ']))\n",
        "\n",
        "\n",
        "    # =============================================================================\n",
        "    # MODEL 2: LSTM\n",
        "    # =============================================================================\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"TRAINING LSTM MODEL\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    lstm_model = LSTMModel(vocab_size).to(device)\n",
        "    print(f\"LSTM Parameters: {sum(p.numel() for p in lstm_model.parameters()):,}\")\n",
        "\n",
        "    lstm_model = train_model(lstm_model, train_loader, dev_loader, epochs=8)\n",
        "\n",
        "    # Test LSTM\n",
        "    lstm_test_acc, lstm_test_f1, lstm_true, lstm_pred = evaluate_model(lstm_model, test_loader)\n",
        "    print(f\"LSTM Test - Accuracy: {lstm_test_acc:.4f}, F1: {lstm_test_f1:.4f}\")\n",
        "    print(\"\\nLSTM Confusion Matrix:\")\n",
        "    lstm_conf_matrix = confusion_matrix(lstm_true, lstm_pred)\n",
        "    cm_df_lstm = pd.DataFrame(lstm_conf_matrix, index=['Actual OBJ', 'Actual SUBJ'], columns=['Predicted OBJ', 'Predicted SUBJ'])\n",
        "    print(cm_df_lstm)\n",
        "    print(\"\\nLSTM Classification Report:\")\n",
        "    print(classification_report(lstm_true, lstm_pred, target_names=['OBJ', 'SUBJ']))\n",
        "\n",
        "\n",
        "    # =============================================================================\n",
        "    # MODEL 3: CNN + LSTM\n",
        "    # =============================================================================\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"TRAINING CNN+LSTM MODEL\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    combined_model = CNNLSTMModel(vocab_size).to(device)\n",
        "    print(f\"Combined Parameters: {sum(p.numel() for p in combined_model.parameters()):,}\")\n",
        "\n",
        "    combined_model = train_model(combined_model, train_loader, dev_loader, epochs=10)\n",
        "\n",
        "    # Test Combined\n",
        "    combined_test_acc, combined_test_f1, combined_true, combined_pred = evaluate_model(combined_model, test_loader)\n",
        "    print(f\"Combined Test - Accuracy: {combined_test_acc:.4f}, F1: {combined_test_f1:.4f}\")\n",
        "    print(\"\\nCombined Confusion Matrix:\")\n",
        "    combined_conf_matrix = confusion_matrix(combined_true, combined_pred)\n",
        "    cm_df_combined = pd.DataFrame(combined_conf_matrix, index=['Actual OBJ', 'Actual SUBJ'], columns=['Predicted OBJ', 'Predicted SUBJ'])\n",
        "    print(cm_df_combined)\n",
        "    print(\"\\nCombined Classification Report:\")\n",
        "    print(classification_report(combined_true, combined_pred, target_names=['OBJ', 'SUBJ']))\n",
        "\n",
        "\n",
        "    # =============================================================================\n",
        "    # FINAL RESULTS COMPARISON\n",
        "    # =============================================================================\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"FINAL RESULTS COMPARISON\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"CNN Model      - Accuracy: {cnn_test_acc:.4f}, F1: {cnn_test_f1:.4f}\")\n",
        "    print(f\"LSTM Model     - Accuracy: {lstm_test_acc:.4f}, F1: {lstm_test_f1:.4f}\")\n",
        "    print(f\"Combined Model - Accuracy: {combined_test_acc:.4f}, F1: {combined_test_f1:.4f}\")\n",
        "\n",
        "    # Find best model\n",
        "    models_results = [\n",
        "        (\"CNN\", cnn_test_f1, cnn_true, cnn_pred),\n",
        "        (\"LSTM\", lstm_test_f1, lstm_true, lstm_pred),\n",
        "        (\"Combined\", combined_test_f1, combined_true, combined_pred)\n",
        "    ]\n",
        "\n",
        "    best_name, best_f1, best_true, best_pred = max(models_results, key=lambda x: x[1])\n",
        "    print(f\"\\nBest Model: {best_name} with F1 Score: {best_f1:.4f}\")\n",
        "\n",
        "    # Detailed report for best model\n",
        "    print(f\"\\nDetailed Classification Report for {best_name} Model:\")\n",
        "    print(classification_report(best_true, best_pred, target_names=['OBJ', 'SUBJ']))\n",
        "\n",
        "    print(f\"\\nConfusion Matrix for Best Model ({best_name}):\")\n",
        "    best_conf_matrix = confusion_matrix(best_true, best_pred)\n",
        "    cm_df_best = pd.DataFrame(best_conf_matrix, index=['Actual OBJ', 'Actual SUBJ'], columns=['Predicted OBJ', 'Predicted SUBJ'])\n",
        "    print(cm_df_best)\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# 9. PREDICTION FUNCTION\n",
        "# =============================================================================\n",
        "\n",
        "def predict_text(text, model_path):\n",
        "    \"\"\"Predict single text\"\"\"\n",
        "    # Load model\n",
        "    checkpoint = torch.load(model_path)\n",
        "    vocab = checkpoint['vocab']\n",
        "    model_type = checkpoint['model_type']\n",
        "    vocab_size = checkpoint['vocab_size']\n",
        "\n",
        "    # Initialize model based on type\n",
        "    if model_type == 'CNN':\n",
        "        model = CNNModel(vocab_size)\n",
        "    elif model_type == 'LSTM':\n",
        "        model = LSTMModel(vocab_size)\n",
        "    elif model_type == 'Combined':\n",
        "        model = CNNLSTMModel(vocab_size)\n",
        "\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    # Process text\n",
        "    sequence = text_to_sequence(text, vocab)\n",
        "    input_tensor = torch.tensor([sequence], dtype=torch.long).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(input_tensor)\n",
        "        probabilities = F.softmax(output, dim=1)\n",
        "        prediction = torch.argmax(output, dim=1)\n",
        "\n",
        "    label = \"SUBJ\" if prediction.item() == 1 else \"OBJ\"\n",
        "    confidence = probabilities[0][prediction].item()\n",
        "\n",
        "    return label, confidence\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfHZQtUjNdAw",
        "outputId": "015b05b6-1286-4025-e5aa-919b23461620"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading datasets...\n",
            "Train: 830, Dev: 462, Test: 300\n",
            "Building vocabulary...\n",
            "Vocabulary size: 8041\n",
            "\n",
            "==================================================\n",
            "TRAINING CNN MODEL\n",
            "==================================================\n",
            "CNN Parameters: 1,221,934\n",
            "Epoch 1/8\n",
            "Train Loss: 0.6992\n",
            "Val Accuracy: 0.4805, Val F1: 0.3119\n",
            "----------------------------------------\n",
            "Epoch 2/8\n",
            "Train Loss: 0.6209\n",
            "Val Accuracy: 0.4805, Val F1: 0.3119\n",
            "----------------------------------------\n",
            "Epoch 3/8\n",
            "Train Loss: 0.5244\n",
            "Val Accuracy: 0.4870, Val F1: 0.3470\n",
            "----------------------------------------\n",
            "Epoch 4/8\n",
            "Train Loss: 0.3232\n",
            "Val Accuracy: 0.4913, Val F1: 0.3492\n",
            "----------------------------------------\n",
            "Epoch 5/8\n",
            "Train Loss: 0.1380\n",
            "Val Accuracy: 0.4935, Val F1: 0.3692\n",
            "----------------------------------------\n",
            "Epoch 6/8\n",
            "Train Loss: 0.0455\n",
            "Val Accuracy: 0.4978, Val F1: 0.3939\n",
            "----------------------------------------\n",
            "Epoch 7/8\n",
            "Train Loss: 0.0191\n",
            "Val Accuracy: 0.5152, Val F1: 0.4547\n",
            "----------------------------------------\n",
            "Epoch 8/8\n",
            "Train Loss: 0.0118\n",
            "Val Accuracy: 0.5152, Val F1: 0.4396\n",
            "----------------------------------------\n",
            "CNN Test - Accuracy: 0.6200, F1: 0.6124\n",
            "\n",
            "CNN Confusion Matrix:\n",
            "             Predicted OBJ  Predicted SUBJ\n",
            "Actual OBJ             163              52\n",
            "Actual SUBJ             62              23\n",
            "\n",
            "CNN Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         OBJ       0.72      0.76      0.74       215\n",
            "        SUBJ       0.31      0.27      0.29        85\n",
            "\n",
            "    accuracy                           0.62       300\n",
            "   macro avg       0.52      0.51      0.51       300\n",
            "weighted avg       0.61      0.62      0.61       300\n",
            "\n",
            "\n",
            "==================================================\n",
            "TRAINING LSTM MODEL\n",
            "==================================================\n",
            "LSTM Parameters: 1,721,858\n",
            "Epoch 1/8\n",
            "Train Loss: 0.6602\n",
            "Val Accuracy: 0.4805, Val F1: 0.3119\n",
            "----------------------------------------\n",
            "Epoch 2/8\n",
            "Train Loss: 0.6366\n",
            "Val Accuracy: 0.5152, Val F1: 0.4097\n",
            "----------------------------------------\n",
            "Epoch 3/8\n",
            "Train Loss: 0.5640\n",
            "Val Accuracy: 0.5390, Val F1: 0.4931\n",
            "----------------------------------------\n",
            "Epoch 4/8\n",
            "Train Loss: 0.4625\n",
            "Val Accuracy: 0.5455, Val F1: 0.5266\n",
            "----------------------------------------\n",
            "Epoch 5/8\n",
            "Train Loss: 0.3091\n",
            "Val Accuracy: 0.5433, Val F1: 0.5239\n",
            "----------------------------------------\n",
            "Epoch 6/8\n",
            "Train Loss: 0.1900\n",
            "Val Accuracy: 0.5346, Val F1: 0.5346\n",
            "----------------------------------------\n",
            "Epoch 7/8\n",
            "Train Loss: 0.1153\n",
            "Val Accuracy: 0.5195, Val F1: 0.5021\n",
            "----------------------------------------\n",
            "Epoch 8/8\n",
            "Train Loss: 0.0467\n",
            "Val Accuracy: 0.5390, Val F1: 0.5147\n",
            "----------------------------------------\n",
            "LSTM Test - Accuracy: 0.6100, F1: 0.6167\n",
            "\n",
            "LSTM Confusion Matrix:\n",
            "             Predicted OBJ  Predicted SUBJ\n",
            "Actual OBJ             151              64\n",
            "Actual SUBJ             53              32\n",
            "\n",
            "LSTM Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         OBJ       0.74      0.70      0.72       215\n",
            "        SUBJ       0.33      0.38      0.35        85\n",
            "\n",
            "    accuracy                           0.61       300\n",
            "   macro avg       0.54      0.54      0.54       300\n",
            "weighted avg       0.62      0.61      0.62       300\n",
            "\n",
            "\n",
            "==================================================\n",
            "TRAINING CNN+LSTM MODEL\n",
            "==================================================\n",
            "Combined Parameters: 1,490,818\n",
            "Epoch 1/10\n",
            "Train Loss: 0.6702\n",
            "Val Accuracy: 0.4805, Val F1: 0.3119\n",
            "----------------------------------------\n",
            "Epoch 2/10\n",
            "Train Loss: 0.6516\n",
            "Val Accuracy: 0.4805, Val F1: 0.3119\n",
            "----------------------------------------\n",
            "Epoch 3/10\n",
            "Train Loss: 0.6186\n",
            "Val Accuracy: 0.4805, Val F1: 0.3119\n",
            "----------------------------------------\n",
            "Epoch 4/10\n",
            "Train Loss: 0.4791\n",
            "Val Accuracy: 0.5693, Val F1: 0.5635\n",
            "----------------------------------------\n",
            "Epoch 5/10\n",
            "Train Loss: 0.1735\n",
            "Val Accuracy: 0.5043, Val F1: 0.3952\n",
            "----------------------------------------\n",
            "Epoch 6/10\n",
            "Train Loss: 0.0654\n",
            "Val Accuracy: 0.5065, Val F1: 0.4069\n",
            "----------------------------------------\n",
            "Epoch 7/10\n",
            "Train Loss: 0.0455\n",
            "Val Accuracy: 0.5628, Val F1: 0.5354\n",
            "----------------------------------------\n",
            "Epoch 8/10\n",
            "Train Loss: 0.0281\n",
            "Val Accuracy: 0.5714, Val F1: 0.5552\n",
            "----------------------------------------\n",
            "Epoch 9/10\n",
            "Train Loss: 0.0149\n",
            "Val Accuracy: 0.5606, Val F1: 0.5304\n",
            "----------------------------------------\n",
            "Epoch 10/10\n",
            "Train Loss: 0.0069\n",
            "Val Accuracy: 0.5584, Val F1: 0.5318\n",
            "----------------------------------------\n",
            "Combined Test - Accuracy: 0.6567, F1: 0.6441\n",
            "\n",
            "Combined Confusion Matrix:\n",
            "             Predicted OBJ  Predicted SUBJ\n",
            "Actual OBJ             172              43\n",
            "Actual SUBJ             60              25\n",
            "\n",
            "Combined Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         OBJ       0.74      0.80      0.77       215\n",
            "        SUBJ       0.37      0.29      0.33        85\n",
            "\n",
            "    accuracy                           0.66       300\n",
            "   macro avg       0.55      0.55      0.55       300\n",
            "weighted avg       0.64      0.66      0.64       300\n",
            "\n",
            "\n",
            "============================================================\n",
            "FINAL RESULTS COMPARISON\n",
            "============================================================\n",
            "CNN Model      - Accuracy: 0.6200, F1: 0.6124\n",
            "LSTM Model     - Accuracy: 0.6100, F1: 0.6167\n",
            "Combined Model - Accuracy: 0.6567, F1: 0.6441\n",
            "\n",
            "Best Model: Combined with F1 Score: 0.6441\n",
            "\n",
            "Detailed Classification Report for Combined Model:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         OBJ       0.74      0.80      0.77       215\n",
            "        SUBJ       0.37      0.29      0.33        85\n",
            "\n",
            "    accuracy                           0.66       300\n",
            "   macro avg       0.55      0.55      0.55       300\n",
            "weighted avg       0.64      0.66      0.64       300\n",
            "\n",
            "\n",
            "Confusion Matrix for Best Model (Combined):\n",
            "             Predicted OBJ  Predicted SUBJ\n",
            "Actual OBJ             172              43\n",
            "Actual SUBJ             60              25\n"
          ]
        }
      ]
    }
  ]
}